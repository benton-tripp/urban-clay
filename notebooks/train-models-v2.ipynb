{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(19)\n",
    "\n",
    "# Path to save the final DataFrame\n",
    "output_pkl_path = \"../data/data_final.pkl\"\n",
    "with open(output_pkl_path, \"rb\") as f:\n",
    "    gdf = pkl.load(f)\n",
    "    \n",
    "to_pred_gdf = gdf.loc[gdf['date'] >= pd.to_datetime('2017-01-01 00:00:00')].reset_index(drop=True)\n",
    "gdf = gdf.loc[gdf['date'] < pd.to_datetime('2017-01-01 00:00:00')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = gdf['tile_index'].unique().tolist()\n",
    "random.shuffle(tiles)\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_index = int(train_ratio * len(tiles))\n",
    "train_tiles = tiles[:split_index] \n",
    "test_tiles = tiles[split_index:]  \n",
    "\n",
    "train_gdf = gdf.loc[gdf['tile_index'].isin(train_tiles)]\n",
    "test_gdf = gdf.loc[gdf['tile_index'].isin(test_tiles)]\n",
    "\n",
    "X_cols = [col for col in gdf.columns if col.startswith('feature')]\n",
    "y_col = 'urban_imperviousness'\n",
    "\n",
    "X_train = train_gdf[X_cols]\n",
    "y_train = np.stack(train_gdf[y_col].values).reshape(-1, 3, 3) # The target is a 3x3 array (originally a raster tile)\n",
    "\n",
    "X_test = test_gdf[X_cols]\n",
    "y_test = np.stack(test_gdf[y_col].values).reshape(-1, 3, 3)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1, 9), dtype=torch.float32)  # Flattened 3x3 grids\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.reshape(-1, 9), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14289, 768)\n",
      "(14289, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.values.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction (3x3 grid):\n",
      " [[0.03153893 0.03276088 0.03203874]\n",
      " [0.03237038 0.03245637 0.03228426]\n",
      " [0.03272095 0.03256148 0.03270835]]\n",
      "Baseline MSE on Test Set: 0.004747930448502302\n",
      "Baseline MAE on Test Set: 0.038547333329916\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model\n",
    "\n",
    "# Calculate the mean urban imperviousness for each cell in the 3x3 grid across the training set\n",
    "baseline_prediction = np.mean(y_train, axis=0)\n",
    "print(\"Baseline prediction (3x3 grid):\\n\", baseline_prediction)\n",
    "\n",
    "# Flatten the true and predicted 3x3 grids to apply the metrics for the test set\n",
    "y_test_flat = y_test.reshape(-1, 9)  # Flatten each 3x3 grid in y_test to a 9-element vector\n",
    "\n",
    "# Repeat the baseline prediction for each sample in y_test for comparison\n",
    "baseline_predictions_test = np.tile(baseline_prediction.flatten(), (y_test_flat.shape[0], 1))\n",
    "\n",
    "# Calculate baseline metrics on the test set\n",
    "mse_baseline_test = mean_squared_error(y_test_flat, baseline_predictions_test)\n",
    "mae_baseline_test = mean_absolute_error(y_test_flat, baseline_predictions_test)\n",
    "\n",
    "print(f\"Baseline MSE on Test Set: {mse_baseline_test}\")\n",
    "print(f\"Baseline MAE on Test Set: {mae_baseline_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train_tensor, y_train_tensor, epochs=100, \n",
    "                criterion=nn.MSELoss(), optimizer=None, lr=0.001):\n",
    "    # Default to Adam optimizer if none is provided\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss every 10 epochs\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0043\n",
      "Epoch [20/100], Loss: 0.0032\n",
      "Epoch [30/100], Loss: 0.0028\n",
      "Epoch [40/100], Loss: 0.0026\n",
      "Epoch [50/100], Loss: 0.0024\n",
      "Epoch [60/100], Loss: 0.0023\n",
      "Epoch [70/100], Loss: 0.0021\n",
      "Epoch [80/100], Loss: 0.0020\n",
      "Epoch [90/100], Loss: 0.0020\n",
      "Epoch [100/100], Loss: 0.0019\n",
      "SimpleNN MSE on Test Set: 0.0022218564990907907\n",
      "SimpleNN MAE on Test Set: 0.024465523660182953\n"
     ]
    }
   ],
   "source": [
    "# Simple fully connected (dense) neural network \n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=768, output_size=9, hidden_units=128):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_units, output_size)  # Output layer matches the size of the 3x3 grid\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Train the model using the train_model function\n",
    "simple_nn_model = SimpleNN(input_size=768, output_size=9, hidden_units=128)\n",
    "trained_simple_nn_model = train_model(\n",
    "    model=simple_nn_model,  \n",
    "    X_train_tensor=X_train_tensor,\n",
    "    y_train_tensor=y_train_tensor,\n",
    "    epochs=100,  \n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(simple_nn_model.parameters(), lr=0.001)\n",
    ")\n",
    "\n",
    "# Prediction on test data\n",
    "with torch.no_grad():\n",
    "    y_test_pred = trained_simple_nn_model(X_test_tensor)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_test = nn.MSELoss()(y_test_pred, y_test_tensor).item()\n",
    "mae_test = nn.L1Loss()(y_test_pred, y_test_tensor).item()\n",
    "\n",
    "print(f\"SimpleNN MSE on Test Set: {mse_test}\")\n",
    "print(f\"SimpleNN MAE on Test Set: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0046\n",
      "Epoch [20/100], Loss: 0.0032\n",
      "Epoch [30/100], Loss: 0.0028\n",
      "Epoch [40/100], Loss: 0.0026\n",
      "Epoch [50/100], Loss: 0.0024\n",
      "Epoch [60/100], Loss: 0.0023\n",
      "Epoch [70/100], Loss: 0.0022\n",
      "Epoch [80/100], Loss: 0.0020\n",
      "Epoch [90/100], Loss: 0.0019\n",
      "Epoch [100/100], Loss: 0.0018\n",
      "SimpleNN MSE on Test Set: 0.002130069537088275\n",
      "SimpleNN MAE on Test Set: 0.02332741767168045\n"
     ]
    }
   ],
   "source": [
    "# Deep Fully Connected Neural Network\n",
    "\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_size=768, output_size=9, hidden_units=128):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.fc3 = nn.Linear(hidden_units, output_size)  # Output layer matches 3x3 grid size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train the model using the train_model function\n",
    "deep_nn_model = DeepNN(input_size=768, output_size=9, hidden_units=128)\n",
    "trained_deep_nn_model = train_model(\n",
    "    model=deep_nn_model,  \n",
    "    X_train_tensor=X_train_tensor,\n",
    "    y_train_tensor=y_train_tensor,\n",
    "    epochs=100, \n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(deep_nn_model.parameters(), lr=0.001)\n",
    ")\n",
    "\n",
    "# Prediction on test data\n",
    "with torch.no_grad():\n",
    "    y_test_pred = trained_deep_nn_model(X_test_tensor)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_test = nn.MSELoss()(y_test_pred, y_test_tensor).item()\n",
    "mae_test = nn.L1Loss()(y_test_pred, y_test_tensor).item()\n",
    "\n",
    "print(f\"DeepNN MSE on Test Set: {mse_test}\")\n",
    "print(f\"DeepNN MAE on Test Set: {mae_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.0567\n",
      "Epoch [20/200], Loss: 0.0196\n",
      "Epoch [30/200], Loss: 0.0078\n",
      "Epoch [40/200], Loss: 0.0045\n",
      "Epoch [50/200], Loss: 0.0037\n",
      "Epoch [60/200], Loss: 0.0033\n",
      "Epoch [70/200], Loss: 0.0030\n",
      "Epoch [80/200], Loss: 0.0029\n",
      "Epoch [90/200], Loss: 0.0028\n",
      "Epoch [100/200], Loss: 0.0027\n",
      "Epoch [110/200], Loss: 0.0027\n",
      "Epoch [120/200], Loss: 0.0026\n",
      "Epoch [130/200], Loss: 0.0026\n",
      "Epoch [140/200], Loss: 0.0025\n",
      "Epoch [150/200], Loss: 0.0025\n",
      "Epoch [160/200], Loss: 0.0024\n",
      "Epoch [170/200], Loss: 0.0024\n",
      "Epoch [180/200], Loss: 0.0023\n",
      "Epoch [190/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "SimpleNN MSE on Test Set: 0.0023209117352962494\n",
      "SimpleNN MAE on Test Set: 0.02437349036335945\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_size=768, output_size=9, hidden_units=128):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_units = hidden_units  # Store hidden_units as a class attribute\n",
    "        self.output_size = output_size  # Store output_size as a class attribute\n",
    "\n",
    "        # Define a Conv1d layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1)\n",
    "        \n",
    "        # Second fully connected layer to project to the output size\n",
    "        conv_out_size = (hidden_units - 3 + 1) * 16  # Calculating the output size of conv layer\n",
    "        self.fc2 = nn.Linear(conv_out_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fully connected layer followed by ReLU activation\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Reshape to match Conv1d input shape (batch_size, channels, sequence_length)\n",
    "        x = x.view(-1, 1, self.hidden_units)\n",
    "        \n",
    "        # Convolutional layer followed by flattening\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten before passing to the output layer\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train the model using the train_model function\n",
    "cnn_model = CNNModel(input_size=768, output_size=9, hidden_units=128)\n",
    "trained_cnn_model = train_model(\n",
    "    model=cnn_model,  \n",
    "    X_train_tensor=X_train_tensor,\n",
    "    y_train_tensor=y_train_tensor,\n",
    "    epochs=100,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    ")\n",
    "\n",
    "# Prediction on test data\n",
    "with torch.no_grad():\n",
    "    y_test_pred = trained_cnn_model(X_test_tensor)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_test = nn.MSELoss()(y_test_pred, y_test_tensor).item()\n",
    "mae_test = nn.L1Loss()(y_test_pred, y_test_tensor).item()\n",
    "\n",
    "print(f\"CNN MSE on Test Set: {mse_test}\")\n",
    "print(f\"CNN MAE on Test Set: {mae_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0054\n",
      "Epoch [20/100], Loss: 0.0040\n",
      "Epoch [30/100], Loss: 0.0031\n",
      "Epoch [40/100], Loss: 0.0028\n",
      "Epoch [50/100], Loss: 0.0026\n",
      "Epoch [60/100], Loss: 0.0025\n",
      "Epoch [70/100], Loss: 0.0024\n",
      "Epoch [80/100], Loss: 0.0023\n",
      "Epoch [90/100], Loss: 0.0022\n",
      "Epoch [100/100], Loss: 0.0021\n",
      "LSTM MSE on Test Set: 0.0021767104044556618\n",
      "LSTM MAE on Test Set: 0.024041717872023582\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=768, output_size=9, hidden_units=128, lstm_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(input_size=hidden_units, hidden_size=hidden_units, num_layers=lstm_layers, batch_first=True)\n",
    "        self.fc2 = nn.Linear(hidden_units, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Reshape for LSTM: (batch_size, sequence_length, input_size)\n",
    "        x = x.unsqueeze(1)  # Adding a sequence dimension, shape becomes (batch_size, 1, hidden_units)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Take the output of the last LSTM cell\n",
    "        x = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Final fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the LSTM model\n",
    "lstm_model = LSTMModel(input_size=768, output_size=9, hidden_units=128, lstm_layers=1)\n",
    "\n",
    "# Train the model using the `train_model` function\n",
    "trained_lstm_model = train_model(\n",
    "    model=lstm_model,  \n",
    "    X_train_tensor=X_train_tensor,\n",
    "    y_train_tensor=y_train_tensor,\n",
    "    epochs=100,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    ")\n",
    "\n",
    "# Prediction on test data\n",
    "with torch.no_grad():\n",
    "    y_test_pred = trained_lstm_model(X_test_tensor)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_test = nn.MSELoss()(y_test_pred, y_test_tensor).item()\n",
    "mae_test = nn.L1Loss()(y_test_pred, y_test_tensor).item()\n",
    "\n",
    "print(f\"LSTM MSE on Test Set: {mse_test}\")\n",
    "print(f\"LSTM MAE on Test Set: {mae_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
